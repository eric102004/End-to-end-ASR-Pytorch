data:
  corpus:                                 # Pass to dataloader
    # The following depends on corpus
    path: '../LibriSpeech/train-clean-100/1069'                      #change path 3
    name: 'LibriSpeech'
    train_split: ['133699']            #change path  1
    dev_split: [['133709']]           #chnage path   2
    bucketing: True
    batch_size: 16

  audio:                                  # Pass to audio transform
    feat_type: 'fbank'
    feat_dim:  80
    apply_cmvn: False
    delta_order: 1                        # 0: do nothing, 1: add delta, 2: add delta and accelerate
    delta_window_size: 2
    frame_length: 25 # ms
    frame_shift: 10 # ms
    ref_level_db: 20
    min_level_db: -100
    preemphasis_coeff: 0.97

  text:
    mode: 'character'                     # 'character'/'word == phone'/'subword'
    vocab_file: 'corpus/librispeech_char.txt'

hparas:                                   # Experiment hyper-parameters
  valid_step: 10                         #change from 5000 to 100  (4)
  max_step: 5500                         #change from 200k to 5k (5)
  tf_start: 1.0
  tf_end: 1.0
  tf_step: 150000
  optimizer: 'Adadelta'
  lr: 1.0
  eps: 0.00000001                          # 1e-8
  lr_scheduler: 'fixed'                    # 'fixed'/'warmup'
  curriculum: 0
  val_mode: 'wer'

model:                                    # Model architecture
  ctc_weight: 0.5                         # Weight for CTC loss
  encoder:
    vgg: 0                                # 4x reduction on time feature extraction
    vgg_freq: -1
    vgg_low_filt: -1
    module: 'LSTM'                        # 'LSTM'/'GRU'/'Transformer'
    bidirection: True
    dim: [320,320,320,320]
    dropout: [0.2,0.2,0.2,0.2]
    layer_norm: [False,False,False,False]
    proj: [True,True,True,True]           # Linear projection + Tanh after each rnn layer
    sample_rate: [1,2,1,1]
    sample_style: 'drop'                  # 'drop'/'concat'
  attention:
    mode: 'loc'                           # 'dot'/'loc'
    dim: 300
    num_head: 1
    v_proj: False                         # if False and num_head>1, encoder state will be duplicated for each head
    temperature: 0.5                      # scaling factor for attention
    loc_kernel_size: 100                  # just for mode=='loc'
    loc_kernel_num: 10                    # just for mode=='loc'
  decoder:
    module: 'LSTM'                        # 'LSTM'/'GRU'/'Transformer'
    dim: 300
    layer: 1
    dropout: 0

src:
  ckpt: 'ckpt/ex1_syn_sd0/last_att_1241.pth'         #specify the path of pretrain model
